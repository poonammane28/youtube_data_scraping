{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3NoDrD7FRa2",
        "outputId": "9bc827b5-4583-428e-a292-585a6edeea07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-4.27.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.3)\n",
            "Collecting trio~=0.17 (from selenium)\n",
            "  Downloading trio-0.27.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting trio-websocket~=0.9 (from selenium)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2024.12.14)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (24.3.0)\n",
            "Collecting sortedcontainers (from trio~=0.17->selenium)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.10)\n",
            "Collecting outcome (from trio~=0.17->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.2)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
            "Downloading selenium-4.27.1-py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio-0.27.0-py3-none-any.whl (481 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m481.7/481.7 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Installing collected packages: sortedcontainers, wsproto, outcome, trio, trio-websocket, selenium\n",
            "Successfully installed outcome-1.3.0.post0 selenium-4.27.1 sortedcontainers-2.4.0 trio-0.27.0 trio-websocket-0.11.1 wsproto-1.2.0\n"
          ]
        }
      ],
      "source": [
        "pip install selenium beautifulsoup4 pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "import pandas as pd\n",
        "\n",
        "API_KEY = 'AIzaSyA_tEuArbkXDLpggI8PvohE30c3bT9jOiY'\n",
        "YOUTUBE_API_SERVICE_NAME = 'youtube'\n",
        "YOUTUBE_API_VERSION = 'v3'\n",
        "\n",
        "def fetch_youtube_data(genre, max_results=500):\n",
        "    youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, developerKey=API_KEY)\n",
        "    videos = []\n",
        "    next_page_token = None\n",
        "\n",
        "    while len(videos) < max_results:\n",
        "        search_response = youtube.search().list(\n",
        "            q=genre, type='video', part='id', maxResults=50, pageToken=next_page_token\n",
        "        ).execute()\n",
        "\n",
        "        videos += search_response.get('items', [])\n",
        "        next_page_token = search_response.get('nextPageToken', None)\n",
        "        if not next_page_token:\n",
        "            break\n",
        "\n",
        "    video_ids = [video['id']['videoId'] for video in videos]\n",
        "    return video_ids[:max_results]\n",
        "\n",
        "def fetch_video_details(video_ids):\n",
        "    youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, developerKey=API_KEY)\n",
        "    details = []\n",
        "    for i in range(0, len(video_ids), 50):\n",
        "        response = youtube.videos().list(\n",
        "            part='snippet,contentDetails,statistics',\n",
        "            id=','.join(video_ids[i:i+50])\n",
        "        ).execute()\n",
        "        details.extend(response['items'])\n",
        "    return details\n",
        "\n",
        "def main():\n",
        "    genre = input(\"Enter genre: \")\n",
        "    video_ids = fetch_youtube_data(genre)\n",
        "    details = fetch_video_details(video_ids)\n",
        "\n",
        "    # Process data and save to CSV\n",
        "    data = []\n",
        "    for video in details:\n",
        "        snippet = video['snippet']\n",
        "        stats = video.get('statistics', {})\n",
        "        data.append({\n",
        "            'Video URL': f\"https://www.youtube.com/watch?v={video['id']}\",\n",
        "            'Title': snippet.get('title'),\n",
        "            'Description': snippet.get('description'),\n",
        "            'Channel Title': snippet.get('channelTitle'),\n",
        "            'View Count': stats.get('viewCount'),\n",
        "            'Comment Count': stats.get('commentCount'),\n",
        "            # Add other fields here\n",
        "        })\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_csv('youtube_data.csv', index=False)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNb_dDejHW8p",
        "outputId": "2a807ac6-80f7-46d4-b4b0-f9c02a186980"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter genre: educational videos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "import pandas as pd\n",
        "\n",
        "API_KEY = 'AIzaSyA_tEuArbkXDLpggI8PvohE30c3bT9jOiY'  # Replace with your API key\n",
        "YOUTUBE_API_SERVICE_NAME = 'youtube'\n",
        "YOUTUBE_API_VERSION = 'v3'\n",
        "\n",
        "def fetch_youtube_data(genre, max_results=500):\n",
        "    youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, developerKey=API_KEY)\n",
        "    videos = []\n",
        "    next_page_token = None\n",
        "\n",
        "    while len(videos) < max_results:\n",
        "        search_response = youtube.search().list(\n",
        "            q=genre, type='video', part='id', maxResults=50, pageToken=next_page_token\n",
        "        ).execute()\n",
        "\n",
        "        videos += search_response.get('items', [])\n",
        "        next_page_token = search_response.get('nextPageToken', None)\n",
        "        if not next_page_token:\n",
        "            break\n",
        "\n",
        "    video_ids = [video['id']['videoId'] for video in videos if 'videoId' in video['id']]\n",
        "    return video_ids[:max_results]\n",
        "\n",
        "def fetch_video_details(video_ids):\n",
        "    youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, developerKey=API_KEY)\n",
        "    details = []\n",
        "    for i in range(0, len(video_ids), 50):\n",
        "        response = youtube.videos().list(\n",
        "            part='snippet,contentDetails,statistics,topicDetails',\n",
        "            id=','.join(video_ids[i:i+50])\n",
        "        ).execute()\n",
        "        details.extend(response['items'])\n",
        "    return details\n",
        "\n",
        "def process_video_data(details):\n",
        "    data = []\n",
        "    for video in details:\n",
        "        snippet = video.get('snippet', {})\n",
        "        stats = video.get('statistics', {})\n",
        "        content_details = video.get('contentDetails', {})\n",
        "        topic_details = video.get('topicDetails', {})\n",
        "\n",
        "        # Extract required fields\n",
        "        data.append({\n",
        "            'Video URL': f\"https://www.youtube.com/watch?v={video['id']}\",\n",
        "            'Title': snippet.get('title'),\n",
        "            'Description': snippet.get('description'),\n",
        "            'Channel Title': snippet.get('channelTitle'),\n",
        "            'Keyword Tags': ', '.join(snippet.get('tags', [])) if 'tags' in snippet else None,\n",
        "            'Video Category': snippet.get('categoryId'),\n",
        "            'Topic Details': ', '.join(topic_details.get('topicCategories', [])) if 'topicCategories' in topic_details else None,\n",
        "            'Video Published at': snippet.get('publishedAt'),\n",
        "            'Video Duration': content_details.get('duration'),\n",
        "            'View Count': stats.get('viewCount'),\n",
        "            'Comment Count': stats.get('commentCount'),\n",
        "            'Captions Available': True if 'caption' in content_details else False,\n",
        "            'Caption Text': None,  # Caption text requires additional API calls\n",
        "            'Location of Recording': snippet.get('location', {}).get('description') if 'location' in snippet else None\n",
        "        })\n",
        "    return data\n",
        "\n",
        "def main():\n",
        "    genre = input(\"Enter genre: \")\n",
        "    video_ids = fetch_youtube_data(genre)\n",
        "    details = fetch_video_details(video_ids)\n",
        "\n",
        "    # Process data and save to CSV\n",
        "    data = process_video_data(details)\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_csv('youtube_data.csv', index=False)\n",
        "    print(\"Data saved to youtube_data.csv\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAYpni4vHXkY",
        "outputId": "26f0efc1-6db7-47d7-f5be-e1c2fbd2e947"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter genre: educational videos\n",
            "Data saved to youtube_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install google-auth google-auth-oauthlib google-auth-httplib2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_-zjg7_Yf8r",
        "outputId": "82c41dc1-59c1-42b3-bfc4-4dc8d1e1dbf0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
            "Requirement already satisfied: google-auth-httplib2 in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib) (1.3.1)\n",
            "Requirement already satisfied: httplib2>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-httplib2) (0.22.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2>=0.19.0->google-auth-httplib2) (3.2.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.2.2)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, redirect, request, url_for\n",
        "from google_auth_oauthlib.flow import Flow\n",
        "import os\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Replace with your client secrets file path\n",
        "CLIENT_SECRETS_FILE = \"/content/client_secret_863239581866-f9ri1ap8cqjfsdgek7jo2np694silhlc.apps.googleusercontent.com.json\"\n",
        "SCOPES = [\"https://www.googleapis.com/auth/youtube.force-ssl\"]\n",
        "flow = Flow.from_client_secrets_file(CLIENT_SECRETS_FILE, SCOPES)\n",
        "flow.redirect_uri = 'http://localhost:8080/callback'\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    authorization_url, state = flow.authorization_url(access_type='offline', include_granted_scopes='true')\n",
        "    return redirect(authorization_url)\n",
        "\n",
        "@app.route('/callback')\n",
        "def callback():\n",
        "    flow.fetch_token(authorization_response=request.url)\n",
        "\n",
        "    # Now you can use the credentials object to interact with the YouTube API\n",
        "    credentials = flow.credentials\n",
        "    return f'Access granted! Credentials: {credentials.token}'\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(port=8080)\n"
      ],
      "metadata": {
        "id": "h6sXMqHnnOF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import google.auth\n",
        "from google_auth_oauthlib.flow import InstalledAppFlow\n",
        "from googleapiclient.discovery import build\n",
        "import pandas as pd\n",
        "\n",
        "# OAuth 2.0 Client Credentials (downloaded from Google Cloud Console)\n",
        "CLIENT_SECRETS_FILE = '/content/client_secret_863239581866-f9ri1ap8cqjfsdgek7jo2np694silhlc.apps.googleusercontent.com.json'\n",
        "\n",
        "# The scope for YouTube API access\n",
        "SCOPES = ['https://www.googleapis.com/auth/youtube.force-ssl']\n",
        "\n",
        "def authenticate_youtube_api():\n",
        "    # Use OAuth 2.0 for authentication\n",
        "    flow = InstalledAppFlow.from_client_secrets_file(CLIENT_SECRETS_FILE, SCOPES)\n",
        "\n",
        "    # Get the authorization URL to manually authenticate\n",
        "    auth_url, _ = flow.authorization_url(prompt='consent')\n",
        "    print(f\"Please go to this URL: {auth_url}\")\n",
        "\n",
        "    # After visiting the URL, the user should receive an authorization code\n",
        "    auth_code = input(\"Enter the authorization code: \")\n",
        "\n",
        "    # Exchange the authorization code for credentials\n",
        "    flow.fetch_token(authorization_response=auth_code)\n",
        "\n",
        "    # Create the YouTube API client\n",
        "    credentials = flow.credentials\n",
        "    youtube = build('youtube', 'v3', credentials=credentials)\n",
        "    return youtube\n",
        "\n",
        "def fetch_youtube_data(genre, max_results=500, youtube=None):\n",
        "    videos = []\n",
        "    next_page_token = None\n",
        "\n",
        "    while len(videos) < max_results:\n",
        "        search_response = youtube.search().list(\n",
        "            q=genre, type='video', part='id', maxResults=50, pageToken=next_page_token\n",
        "        ).execute()\n",
        "\n",
        "        videos += search_response.get('items', [])\n",
        "        next_page_token = search_response.get('nextPageToken', None)\n",
        "        if not next_page_token:\n",
        "            break\n",
        "\n",
        "    video_ids = [video['id']['videoId'] for video in videos if 'videoId' in video['id']]\n",
        "    return video_ids[:max_results]\n",
        "\n",
        "def fetch_video_details(video_ids, youtube):\n",
        "    details = []\n",
        "    for i in range(0, len(video_ids), 50):\n",
        "        response = youtube.videos().list(\n",
        "            part='snippet,contentDetails,statistics,topicDetails',\n",
        "            id=','.join(video_ids[i:i+50])\n",
        "        ).execute()\n",
        "        details.extend(response['items'])\n",
        "    return details\n",
        "\n",
        "def fetch_video_captions(youtube, video_id):\n",
        "    try:\n",
        "        captions_response = youtube.captions().list(part='snippet', videoId=video_id).execute()\n",
        "        if 'items' in captions_response:\n",
        "            caption_id = captions_response['items'][0]['id']\n",
        "            caption_response = youtube.captions().download(id=caption_id).execute()\n",
        "            return caption_response.get('body', None)\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching captions for video {video_id}: {e}\")\n",
        "    return None\n",
        "\n",
        "def process_video_data(details, youtube):\n",
        "    data = []\n",
        "    for video in details:\n",
        "        snippet = video.get('snippet', {})\n",
        "        stats = video.get('statistics', {})\n",
        "        content_details = video.get('contentDetails', {})\n",
        "        topic_details = video.get('topicDetails', {})\n",
        "\n",
        "        # Fetch caption text\n",
        "        caption_text = fetch_video_captions(youtube, video['id']) if 'caption' in content_details else None\n",
        "\n",
        "        # Extract required fields\n",
        "        data.append({\n",
        "            'Video URL': f\"https://www.youtube.com/watch?v={video['id']}\",\n",
        "            'Title': snippet.get('title'),\n",
        "            'Description': snippet.get('description'),\n",
        "            'Channel Title': snippet.get('channelTitle'),\n",
        "            'Keyword Tags': ', '.join(snippet.get('tags', [])) if 'tags' in snippet else None,\n",
        "            'Video Category': snippet.get('categoryId'),\n",
        "            'Topic Details': ', '.join(topic_details.get('topicCategories', [])) if 'topicCategories' in topic_details else None,\n",
        "            'Video Published at': snippet.get('publishedAt'),\n",
        "            'Video Duration': content_details.get('duration'),\n",
        "            'View Count': stats.get('viewCount'),\n",
        "            'Comment Count': stats.get('commentCount'),\n",
        "            'Captions Available': True if 'caption' in content_details else False,\n",
        "            'Caption Text': caption_text,\n",
        "            'Location of Recording': snippet.get('location', {}).get('description') if 'location' in snippet else None\n",
        "        })\n",
        "    return data\n",
        "\n",
        "def main():\n",
        "    youtube = authenticate_youtube_api()  # Authenticate with OAuth2\n",
        "    genre = input(\"Enter genre: \")\n",
        "    video_ids = fetch_youtube_data(genre, youtube=youtube)\n",
        "    details = fetch_video_details(video_ids, youtube=youtube)\n",
        "\n",
        "    # Process data and save to CSV\n",
        "    data = process_video_data(details, youtube)\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_csv('youtube_data.csv', index=False)\n",
        "    print(\"Data saved to youtube_data.csv\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zlx1Jcwbcms9",
        "outputId": "764769c1-e365-41df-8ab9-f4cfd9d1dedd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please go to this URL: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=863239581866-f9ri1ap8cqjfsdgek7jo2np694silhlc.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fyoutube.force-ssl&state=pPoawD5TrQYan5k6EwdfIsL4PKAQoq&prompt=consent&access_type=offline\n"
          ]
        }
      ]
    }
  ]
}